{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SORT SUNSET BAY HYDROPHONE CHUNKS FROM AWS\n",
    "## Isabelle Brandicourt, 10-31-2024\n",
    "\n",
    "### Step 1: open portal to AWS and look at the available buckets for sunset bay hydrophone, convert UNIX time to UTC to PST for ease of understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "\n",
    "# Set up the S3 client with unsigned configuration\n",
    "s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = 'audio-orcasound-net'\n",
    "prefix = 'rpi_sunset_bay/hls/'\n",
    "directories, num_directories = [], []\n",
    "files = []\n",
    "\n",
    "# List objects in the specified bucket and prefix\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix, Delimiter='/')\n",
    "\n",
    "# Print directory (pseudo-folder) names\n",
    "if 'CommonPrefixes' in response:\n",
    "    for prefix_info in response['CommonPrefixes']:\n",
    "        directories.append(prefix_info['Prefix'])\n",
    "        # Get the numeric part of the directory name\n",
    "        num = prefix_info['Prefix'].split('/')[-2]  # Get the last directory name before the trailing '/'\n",
    "        num_directories.append(int(num))\n",
    "\n",
    "# Print file names\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        files.append(obj['Key'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read the CSV with the chunks of data that we want to look at from OrcaSound\n",
    "Now the data will be sorted into multiple dataframes, each holding all of the entries that we are curious about from a specific bucket in AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "\n",
    "file_path = 'orcasound_entries_oct.xlsx'\n",
    "orcasound_entries = pd.read_excel(file_path)\n",
    "buckets = orcasound_entries['aws_bucket'].unique()\n",
    "sorted_by_bucket = {name: group for name, group in orcasound_entries.groupby('aws_bucket')}\n",
    "\n",
    "# print(orcasound_entries.head())\n",
    "orcasound_entries['unix'] = pd.to_datetime(orcasound_entries['utc_date_time'], format='%Y-%m-%d_%H.%M.%S').astype(int) // 10**9\n",
    "# print('\\nNEW FRAME:\\n', orcasound_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose a specific time segment to analyze\n",
    "Enter your timestamps of interest and those data files will be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time: 2024-10-29 20:26:30-07:00 Ending time: 2024-10-29 20:26:40-07:00\n",
      "Using bucket 1730185224\n",
      "Live start: 7354, Live end: 7361\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "import os\n",
    "\n",
    "year = 2024\n",
    "month = 10\n",
    "day = 29\n",
    "start_hour = 20\n",
    "start_min = 26\n",
    "start_sec = 30\n",
    "end_hour = 20\n",
    "end_min = 26\n",
    "end_sec = 40\n",
    "\n",
    "pst = pytz.timezone('America/Los_Angeles')\n",
    "start_time = pst.localize(datetime(year, month, day, start_hour, start_min, start_sec))\n",
    "end_time = pst.localize(datetime(year, month, day, end_hour, end_min, end_sec))\n",
    "print('Starting time:', start_time, 'Ending time:', end_time)\n",
    "\n",
    "start_unix_time = int(start_time.timestamp())\n",
    "end_unix_time = int(end_time.timestamp())\n",
    "\n",
    "below_target = [val for val in buckets if val < start_unix_time]\n",
    "use_bucket = int(max(below_target))\n",
    "print(f'Using bucket {use_bucket}')\n",
    "\n",
    "start_live = round((start_unix_time - use_bucket)/10)-3\n",
    "end_live = round((end_unix_time - use_bucket)/10)+3\n",
    "print(f'Live start: {start_live}, Live end: {end_live}')\n",
    "\n",
    "local_folder = f'{use_bucket}'\n",
    "local_files = []\n",
    "os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "s3_keys = []\n",
    "\n",
    "if int(local_folder) in sorted_by_bucket:\n",
    "    by_bucket = sorted_by_bucket[int(local_folder)]\n",
    "    s = start_live\n",
    "    while s <= end_live:\n",
    "        aws_filename = f'live{s}.ts'\n",
    "        s3_key = f'rpi_sunset_bay/hls/{use_bucket}/{aws_filename}'\n",
    "        download_path = os.path.join(local_folder, aws_filename)\n",
    "\n",
    "        try:\n",
    "            s3_client.download_file(bucket_name, s3_key, download_path)\n",
    "            local_files.append(download_path)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred in downloading the audio files from AWS: {e}\")\n",
    "\n",
    "        s += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Concatenate the selected section and save it as a single file with the time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files concatenated successfully into ts_chunks/2024-10-29_20.26.30_to_2024-10-29_20.26.40.ts\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "chunk_name = os.path.join('ts_chunks', start_time.strftime('%Y-%m-%d_%H.%M.%S') + '_to_' + end_time.strftime('%Y-%m-%d_%H.%M.%S'))\n",
    "if local_files:\n",
    "    with open('temp_concat.txt', 'w') as f:\n",
    "        for local_file in local_files:\n",
    "            f.write(f\"file '{local_file}'\\n\")\n",
    "\n",
    "    # The ffmpeg command\n",
    "    command = [\n",
    "        'ffmpeg',\n",
    "        '-f', 'concat',\n",
    "        '-safe', '0',\n",
    "        '-i', 'temp_concat.txt',\n",
    "        '-c', 'copy',\n",
    "        '-y',\n",
    "        chunk_name + '.ts'\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"Files concatenated successfully into {chunk_name}.ts\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred during concatenation: {e}\")\n",
    "\n",
    "    os.remove('temp_concat.txt')\n",
    "    for local_file in local_files:\n",
    "        os.remove(local_file)  # Remove each local .ts file\n",
    "    os.rmdir(local_folder)  # Remove the local folder\n",
    "else:\n",
    "    print(\"No files to concatenate.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
